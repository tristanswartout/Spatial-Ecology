---
title: "Swartout Lab 8"
output: html_notebook
---

```{r}
require(tidyterra)
require(dismo)
require(tidyverse)
require(terra)
require(predicts)
require(ggnewscale)
require(mgcv)
require(randomForest)
require(maxnet)
require(enmSdmX)
require(gbm)
require(landscapemetrics)
require(raster)
```

# Challenge 1 (4 points)

In the lab, we created 6 species distribution models (SDMs) for the same species using 6 different techniques. Plot the maps generated from (1) the bioclim envelope function, (2) the GLM model, and (3) the random forest model next to one another. What similarities and differences do you notice among these maps? What might explain some of these differences?

Lets download the presence data

```{r}
vathData = read.csv('https://raw.githubusercontent.com/ValenteJJ/SpatialEcology/main/Week8/vath_2004.csv')

vathPres = vathData %>% filter(VATH==1)
vathAbs = vathData %>% filter(VATH==0)

vathPresXy = as.matrix(vathPres %>% select(EASTING, NORTHING))
vathAbsXy = as.matrix(vathAbs %>% select(EASTING, NORTHING))
```

Lets download the validation data

```{r}
vathVal = read.csv('https://raw.githubusercontent.com/ValenteJJ/SpatialEcology/main/Week8/vath_VALIDATION.csv')

vathValPres = vathVal %>% filter(VATH==1)
vathValAbs = vathVal %>% filter(VATH==0)

vathValXy = as.matrix(vathVal %>% select(EASTING, NORTHING))
vathValPresXy = as.matrix(vathValPres %>% select(EASTING, NORTHING))
vathValAbsXy = as.matrix(vathValAbs %>% select(EASTING, NORTHING))
```


Lets download the layers data

```{r}
elev = rast('https://github.com/ValenteJJ/SpatialEcology/raw/main/Week8/elevation.tif')
canopy = rast('https://github.com/ValenteJJ/SpatialEcology/raw/main/Week8/canopy.tif')
mesic = rast('https://github.com/ValenteJJ/SpatialEcology/raw/main/Week8/mesic.tif')
precip = rast('https://github.com/ValenteJJ/SpatialEcology/raw/main/Week8/precip.tif')

crs(elev) = crs(mesic)
crs(canopy) = crs(mesic)


mesic = resample(x = mesic, y = elev, 'near')
precip = resample(x = precip, y = elev, 'bilinear')

mesic = mask(mesic, elev)
precip = mask(precip, elev)
```

Lets make mesic 1km

```{r}
probMatrix = focalMat(mesic, 1000, type='circle', fillNA=FALSE)
mesic1km = focal(mesic, probMatrix, fun='sum')
```

Lets setup the layers

```{r}
layers = c(canopy, elev, mesic, mesic1km, precip)
names(layers) = c('canopy', 'elev', 'mesic', 'mesic1km', 'precip')
plot(layers)
```

Lets get the layers names setup

```{r}
layers = c(canopy, elev, mesic1km, precip)
names(layers) = c('canopy', 'elev', 'mesic1km', 'precip')
```


Get the background points ready

```{r}
set.seed(23)

backXy = data.frame(backgroundSample(layers, n=2000, p=vathPresXy))

```

Setup the data

```{r}
presCovs = extract(layers, vathPresXy)
backCovs = extract(layers, backXy)
valCovs = extract(layers, vathValXy)

presCovs = data.frame(vathPresXy, presCovs, pres=1)
backCovs = data.frame(backXy, backCovs, pres=0)
valCovs = data.frame(vathValXy, valCovs)
```


Finishing setup the data

```{r}
presCovs = presCovs[complete.cases(presCovs),]
backCovs = backCovs[complete.cases(backCovs),]
valCovs = valCovs[complete.cases(valCovs),]


backCovs = backCovs %>% select(-ID)
colnames(presCovs)[1:2] = c('x', 'y')

presBackCovs = rbind(presCovs, backCovs)
```

Lets setup the bioclim model

```{r}
tmp = presCovs %>% select(elev, precip, mesic1km, canopy) %>% 
  as.matrix()

bioclim = envelope(tmp)
```

Now the bioclim model

```{r}
bioclimMap = predict(layers, bioclim)
biocplot=plot(bioclimMap)
```


Now the glm model

```{r}
glmModel = glm(pres ~ canopy + elev + I(elev^2) + mesic1km + precip, family='binomial', data=presBackCovs)

glmMap = predict(layers, glmModel, type='response')
glmplot=plot(glmMap)
```

Now the random forest model

```{r}
tuneRF(y = as.factor(presBackCovs$pres), x=presBackCovs[,3:6], stepFactor = 2, ntreeTry = 500)

rfModel = randomForest(as.factor(pres) ~ canopy + elev + mesic1km + precip, data=presBackCovs, mtry=2, ntree=500, na.action = na.omit)

rfMap = predict(layers, rfModel, type='prob', index=2)
rfplot=plot(rfMap)
```
Answer 1:
Looking at the data from the lab example you can notice some differences between maps immediately. For one, the bioclim and random forest models both have much higher probability of detection at a given site compared to the glm model (e.g., 0.8 versus 0.35). The reason bioclim and glm may be different is because a glm accounts for background points (pseudo-absence points) while bioclim is only accounting for presence data and a glm is weighing all variables and their significance while a bioclim is considering each variable on an equal level. A concern with the glm is the more background points you include the lower the detection probability will be based off sample size which may also explain lower probability. In the case of the random forests we use presence and background data to calculate probability of occupancy except now we are boostrapping the data over multiple simulations to determine if a varied thrush will be present at a specific location. When comparing the random forest to the bioclim you will notice the probability scale is the same but far future locations of the random forests have a high probability of a varied thrush being present. This is probability on account of background points being utilized and also the fact we are boostrapping the data to predict presence. To summarize, the random forests model likely a more accurate SDM of varied thrush compared to bioclim because without accounting for background points the bioclim is overestimating presence on the landscape. With the glm model is likely underselling the data because these pseudo absence points will cause lower presence probability with increasing sample size. 

# Challenge 2 (4 points)

When we fit our GLM in lab, we used background points, rather than true absence points, to represent pseudo-absences. Fit the exact same GLM model, only this time use presence and true absence data. That is, replace the background rows in the dataframe with rows that represent actual sites where surveys were completed but Varied Thrush were not detected. Once you've fit the GLM, build a new SDM from this fitted model and visually compare the prediction surface to that built based on the presence-background model. What discrepancies do you notice, and what is your intuition regarding which of these two models is more reliable?

Lets get the validation data setup

```{r}
presCovs2 = extract(layers, vathValPresXy)
absCovs2 = extract(layers, vathValAbsXy)

presCovs2 = data.frame(vathValPresXy, presCovs2, pres=1)
absCovs2 = data.frame(vathValAbsXy, absCovs2, pres=0)
```

Now lets remove any values where we don't have enough info

```{r}
presCovs2 = presCovs2[complete.cases(presCovs2),]
absCovs2 = absCovs2[complete.cases(absCovs2),]

valabspres = rbind(presCovs2, absCovs2)
colnames(valabspres)[1:2] = c('x', 'y')
```


Now lets run the validation model and plot it

```{r}
glmModelabs = glm(pres ~ canopy + elev + I(elev^2) + mesic1km + precip, family='binomial', data=valabspres)

summary(glmModelabs)

glmMap1 = predict(layers, glmModelabs, type='response')
plot(glmMap1)
```
Answer 2: 
You will notice some large differences between the background model and the absence data model. To start, the probability range is much higher with the absence data model (0.8 versus 0.35) this is likely due to it being viable data and not just background points which will lower the probability due to increase sample size. I also notice areas with high probability of presence are much more narrowed down but also a higher probability is calculated. The model with absence data would be the model I would believe every time because it is making less assumptions if the varied thrush is there or not. Background points are treated as absences even if they were not truly. As a result, the background point model is limited with its accurate interpretation. 

# Challenge 3 (4 points)

Now plot the relationship between the 4 explanatory variables and the predicted occupancy values based on the two fitted GLM models (presence-background and presence-absence). Recall that we did this in the latter part of our lab. Do you notice any differences in the covariate patterns between the two models? Does this help you interpret the discrepancies between the predicted surfaces from the two models?

First lets do the elevation model

```{r}
tmp = expand.grid(elev = seq(min(backCovs$elev), max(backCovs$elev), length=1000),
                  canopy = mean(backCovs$canopy),
                  precip = mean(backCovs$precip),
                  mesic1km = mean(backCovs$mesic1km))

elevData = data.frame(glmback = predict(glmModel, tmp, type='response'),
                 glmabs = predict(glmModelabs, tmp, type='response'))%>%
  cbind(tmp) %>% 
  select(glmback:elev) %>% 
  pivot_longer(glmback:glmabs) %>% 
  mutate(variable = 'elevation')
```

Now the canopy model

```{r}
tmp = expand.grid(elev = mean(backCovs$elev),
                  canopy = seq(min(backCovs$canopy), max(backCovs$elev), length=1000),
                  precip = mean(backCovs$precip),
                  mesic1km = mean(backCovs$mesic1km))

canopyData = data.frame(glmback = predict(glmModel, tmp, type='response'),
                 glmabs = predict(glmModelabs, tmp, type='response'))%>%
  cbind(tmp) %>%
  select(glmback:glmabs, canopy) %>% 
  pivot_longer(glmback:glmabs) %>% 
  mutate(variable = 'canopy')
```

Now the precipitation model

```{r}
tmp = expand.grid(elev = mean(backCovs$elev),
                  canopy = mean(backCovs$canopy),
                  precip = seq(min(backCovs$precip), max(backCovs$precip), length=1000),
                  mesic1km = mean(backCovs$mesic1km))

precipData = data.frame(glmback = predict(glmModel, tmp, type='response'),
                 glmabs = predict(glmModelabs, tmp, type='response'))%>%
  cbind(tmp) %>%
  select(glmback:glmabs, precip) %>% 
  pivot_longer(glmback:glmabs) %>% 
  mutate(variable = 'precipitation')
```

Now the mesic data model

```{r}
tmp = expand.grid(elev = mean(backCovs$elev),
                  canopy = mean(backCovs$canopy),
                  precip = mean(backCovs$precip),
                  mesic1km = seq(min(backCovs$mesic1km), max(backCovs$mesic1km), length=1000))

mesicData = data.frame(glmback = predict(glmModel, tmp, type='response'),
                 glmabs = predict(glmModelabs, tmp, type='response'))%>%
  cbind(tmp) %>%
  select(glmback:glmabs, mesic1km) %>% 
  pivot_longer(glmback:glmabs) %>% 
  mutate(variable = 'mesic1km')
```

And finally lets plot it 

```{r}
colnames(elevData)[1] = colnames(canopyData)[1] = colnames(precipData)[1] = colnames(mesicData)[1] = 'xValue'

tmp = rbind(elevData, canopyData, precipData, mesicData)

ggplot(tmp, aes(x=xValue, y=value, color=name))+
  facet_wrap(~variable, scales='free_x')+
  geom_line()+
  theme_bw()+
  theme(panel.grid=element_blank())
```
Answer 3:
You will notice several differences between the two models. To start, our variables for canopy, precipitation and elevation in the absence data model all generally have higher presence probability than the background point model. Mesic however appears to have similar values for both models (possibly due to non-significance in the absence model?). This mainly tells me that the absence model will calculate a high presence probability and reaffirms my belief that this model is more useful because it is providing higher presence and is also likely more realistic because absence data was actually collected instead of pseudo points. 

# Challenge 4 (4 points)

Varied Thrush are considered forest-dependent, and thus one might characterize mesic forests as "habitat" for the species. Calculate the total amount of mesic forest in the study area, and the mean size of the mesic forest patches.

Using the SDM built from the random forest model, convert the landscape into "habitat" and "non-habitat." To do this, choose a threshold value in your SDM and convert all cells with predicted outcomes greater than this threshold to 1 and all cells with predicted values below your threshold to 0. Justify your choice of your threshold value. Now calculate the total amount of habitat and mean size of habitat patches based on this new raster (i.e., create patches of "habitat" based on aggregations of cells you deemed 1). How do the habitat amount and patch size values compare between the mesic forest approach and the SDM-based approach? In what situations might you rely on one map over the other?

First lets get area and mean patch size for the mesic model


```{r}
mesicmn=lsm_c_ca(mesic, directions=8) 
mesicmn

mesicpmn=lsm_c_area_mn(mesic, directions=8)
mesicpmn
```

Lets set a threshold of 0.25 and make it categorical 


```{r}
n=c(0.0,0.25,0, 0.25,0.932,1)
reclass=classify(rfMap,n)
plot(reclass)
```

Now lets calculate the area and mean patch size of the sdm threshold model

```{r}
reclassmn=lsm_c_ca(reclass, directions=8) 
reclassmn

reclassmn=lsm_c_area_mn(reclass, directions=8)
reclassmn
```

Answer 4: I chose 25% as the threshold because anything below 1/4 odds of seeing a varied thrush at a specified spot is fairly low odds. Comparing the mesic forest total area to the threshold habitat total area there is a significant drop. Mesic forest total area was 4,021,700 units while the threshold habitat only made up 286,624 units. Next looking at mean patch size there was also a significant decline. Mesic forest mean patch size was 749.05 units while threshold habitat only had a mean patch size of 17.81 units; quite the difference. If you're just trying to map the general habitat of the species the mesic forest approach would make sense; however, if the species in the area is a critical low levels it would be better to take the SDM approach so you can figure out what specific areas they are inhabiting and protect them. 

# Challenge 5 (4 points)

When we fit the Maxent model in the lab, we used a regularization constant of 1. Fit the model two more times, using regularization (regmult) constants of 0.5 and 3. Construct figures showing the relationship between the 4 explanatory variables and the predicted outcome from these 3 fitted Maxent models. What is the regularization constant doing? Hint: you may need to Google it.

First lets do the original maxnet model

```{r}
pbVect1 = presBackCovs$pres
covs = presBackCovs %>% select(canopy:precip)

maxentModel1 = maxnet(p = pbVect1,
                     data= covs,
                     regmult = 1,
                     classes='lqpht')

plot(maxentModel1, type='logistic')

maxentMap1 = predictMaxNet(maxentModel1, layers, type='logistic')

par(mfrow=c(1,1))
plot(maxentMap1)
```

Now lets do a model with a value of 0.5

```{r}
pbVect0.5 = presBackCovs$pres
covs = presBackCovs %>% select(canopy:precip)

maxentModel0.5 = maxnet(p = pbVect0.5,
                     data= covs,
                     regmult = 0.5,
                     classes='lqpht')

plot(maxentModel0.5, type='logistic')

maxentMap0.5 = predictMaxNet(maxentModel0.5, layers, type='logistic')

par(mfrow=c(1,1))
plot(maxentMap0.5)
```

Now lets do a model with a value of 3


```{r}
pbVect3 = presBackCovs$pres
covs = presBackCovs %>% select(canopy:precip)

maxentModel3 = maxnet(p = pbVect3,
                     data= covs,
                     regmult = 3,
                     classes='lqpht')

plot(maxentModel3, type='logistic')

maxentMap3 = predictMaxNet(maxentModel3, layers, type='logistic')

par(mfrow=c(1,1))
plot(maxentMap3)
```

Answer 5:
Regularization is a technique in machine learning to prevent over or under fitting. Under fitting would be the prediction doesn't match the data at all while over fitting is making the model prediction "to good to be true". The values of regularization represent how the coefficients of the model are penalized. With a low regmult value (e.g., 0.5) we are essentially over fitting the model as a result our presence probability is gonna be lower for a large portion of the area; essentially it is possibly predicting to few areas where varied thrush could be. The opposite case with a high regmult value is the model is over simplified and more the of area will have a higher probability of varied thrush presence which may be inaccurate. To low of a value and you will be over complicating the model and have an underestimate of presence; to high of a value and you will be overestimating presence. 